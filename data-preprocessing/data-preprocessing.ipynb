{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing PSF data for SNR/eigenPSF reconstruction tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pickle\n",
    "import random\n",
    "from ShapePipe.shapepipe.pipeline import file_io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test parameters\n",
    "\n",
    "- CCD = 38\n",
    "- Nb of eigenPSF = 16\n",
    "- Gaussian noise std dev =  0.4e-3 (SNR ~ 40dB)\n",
    "- Total nb of stars (per set) = 50\n",
    "- Train stars = 80% (40 stars)\n",
    "- Test stars = 20% (10 stars)\n",
    "- The star positions of the train/test set are defined at first (randomly) and are maintained throughout all the 50 star sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parameters\n",
    "\n",
    "CCDn = 38\n",
    "eigenPSFn = 16\n",
    "sigmaN = 0.4e-3 # SNR ~ 40dB\n",
    "star_nb = 50\n",
    "train_per = 0.8\n",
    "train_star_nb = np.floor(train_per*star_nb).astype(int)\n",
    "test_star_nb = star_nb - train_star_nb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['vignet', 'e1_true', 'e2_true', 'fwhm', 'CCD_n', 'X', 'Y'])\n",
      "(24823, 51, 51)\n",
      "(24823,)\n",
      "(24823,)\n",
      "(24823,)\n",
      "(24823,)\n",
      "(24823,)\n",
      "(24823,)\n"
     ]
    }
   ],
   "source": [
    "# Import the data from the NPY extension\n",
    "raw_ccd = np.load('../JB-data/npy-data/psf_ccd_38.npy', allow_pickle=True)\n",
    "cat = raw_ccd.item()\n",
    "\n",
    "# Take a look at the data\n",
    "print(cat.keys())\n",
    "print(cat['vignet'].shape)\n",
    "print(cat['e1_true'].shape)\n",
    "print(cat['e2_true'].shape)\n",
    "print(cat['fwhm'].shape)\n",
    "print(cat['CCD_n'].shape)\n",
    "print(cat['X'].shape)\n",
    "print(cat['Y'].shape)\n",
    "\n",
    "total_nb_stars = cat['X'].shape[0]\n",
    "xdim = cat['vignet'][0,:,:].shape[0]\n",
    "ydim = cat['vignet'][0,:,:].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fits saving function\n",
    "\n",
    "def save_fits(vignet, xwin, ywin, train_bool, CCDn, id_nb):\n",
    "    # Save data into the FITS format extension\n",
    "    data = {'VIGNET': vignet, 'XWIN_IMAGE': xwin, 'YWIN_IMAGE': ywin}\n",
    "    \n",
    "    train_path = '/Users/tliaudat/Documents/PhD/codes/venv_p3/tests/preprocessed_data/train/'\n",
    "    test_path = '/Users/tliaudat/Documents/PhD/codes/venv_p3/tests/preprocessed_data/test/'\n",
    "    train_pattern = 'train_star_selection'\n",
    "    test_pattern = 'test_star_selection'\n",
    "    \n",
    "    number_scheme = \"-%2d-%06d\"%(CCDn,id_nb)\n",
    "    ext = '.fits'\n",
    "    \n",
    "    if train_bool == True:\n",
    "        saving_path = train_path + train_pattern + number_scheme + ext\n",
    "    elif train_bool == False:\n",
    "        saving_path = test_path + test_pattern + number_scheme + ext\n",
    "        \n",
    "    fits_file = file_io.FITSCatalog(saving_path,\\\n",
    "        open_mode = file_io.BaseCatalog.OpenMode.ReadWrite, SEx_catalog=True)\n",
    "    fits_file.save_as_fits(data, \\\n",
    "        sex_cat_path = '/Users/tliaudat/Documents/PhD/codes/venv_p3/tests/preprocessed_data/example-fits.fits')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the different star sets (of 50 stars) from the overall star catalog\n",
    "\n",
    "# Prepare the stars\n",
    "X_grid = np.unique(cat['X']) # 5\n",
    "Y_grid = np.unique(cat['Y']) # 10\n",
    "star_id = np.zeros((total_nb_stars,), dtype=int)\n",
    "\n",
    "# Identify each star with its id\n",
    "for it in range(total_nb_stars):\n",
    "    X_coor = np.where(X_grid == cat['X'][it])\n",
    "    Y_coor = np.where(Y_grid == cat['Y'][it])\n",
    "    \n",
    "    star_id[it] = (10*X_coor[0][0] + Y_coor[0][0]).astype(int)\n",
    "    \n",
    "# Count how many stars are there at each position\n",
    "star_quantity = np.zeros((star_nb,), dtype=int)\n",
    "for it in range(star_nb):\n",
    "    star_quantity[it] = np.where(star_id == it)[0].shape[0]\n",
    "    \n",
    "# Number of star sets to be created\n",
    "nb_star_sets = np.min(star_quantity)\n",
    "\n",
    "# Generate the star sets to be used\n",
    "star_sets = np.zeros((star_nb,nb_star_sets), dtype=int)\n",
    "star_counter = np.zeros((nb_star_sets,), dtype=int)\n",
    "\n",
    "for it in range(total_nb_stars):\n",
    "    star_position = star_id[it]\n",
    "    star_set_nb = star_counter[star_position]\n",
    "    \n",
    "    if star_set_nb < nb_star_sets:\n",
    "        star_sets[star_position,star_set_nb] = it\n",
    "        star_counter[star_position] += 1\n",
    "        \n",
    "# Generate the random test positions in the star field\n",
    "# The positions will be maintained throughout the star sets\n",
    "rand_seq = np.random.randn(star_nb).argsort()\n",
    "train_ids = rand_seq[0:train_star_nb]\n",
    "test_ids = rand_seq[train_star_nb:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start each set preparation\n",
    "\n",
    "# Train sets\n",
    "for it_set in range(nb_star_sets):\n",
    "    myset_vignet = np.zeros((train_star_nb,xdim,ydim),dtype=np.float32)\n",
    "    myset_X = np.zeros((train_star_nb,),dtype=np.float64)\n",
    "    myset_Y = np.zeros((train_star_nb,),dtype=np.float64)\n",
    "    \n",
    "    for it_star in range(train_star_nb):\n",
    "        id_tr = train_ids[it_star] # Get the right training id\n",
    "        my_star = star_sets[id_tr,it_set] # Get the right star\n",
    "        \n",
    "        # Star position\n",
    "        myset_X[it_star] = cat['X'][my_star]\n",
    "        myset_Y[it_star] = cat['Y'][my_star]\n",
    "        \n",
    "        # Star image noise addition\n",
    "        star_img = cat['vignet'][my_star,:,:]\n",
    "        myNoise = sigmaN*np.random.randn(xdim,ydim)\n",
    "        myset_vignet[it_star,:,:] = star_img + myNoise\n",
    "    \n",
    "    train_bool = True\n",
    "    save_fits(myset_vignet, myset_X, myset_Y, train_bool, CCDn, it_set)\n",
    "\n",
    "    \n",
    "# Test sets\n",
    "for it_set in range(nb_star_sets):\n",
    "    myset_vignet = np.zeros((test_star_nb,xdim,ydim),dtype=np.float32)\n",
    "    myset_X = np.zeros((test_star_nb,),dtype=np.float64)\n",
    "    myset_Y = np.zeros((test_star_nb,),dtype=np.float64)\n",
    "    \n",
    "    for it_star in range(test_star_nb):\n",
    "        id_tr = test_ids[it_star] # Get the right training id\n",
    "        my_star = star_sets[id_tr,it_set] # Get the right star\n",
    "        \n",
    "        # Star position\n",
    "        myset_X[it_star] = cat['X'][my_star]\n",
    "        myset_Y[it_star] = cat['Y'][my_star]\n",
    "        \n",
    "        # Star image (without noise)\n",
    "        myset_vignet[it_star,:,:] = cat['vignet'][my_star,:,:]\n",
    "    \n",
    "    train_bool = False\n",
    "    save_fits(myset_vignet, myset_X, myset_Y, train_bool, CCDn, it_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the position matrix for the correct plotting\n",
    "np.save('X_unique',np.unique(cat['X']))\n",
    "np.save('Y_unique',np.unique(cat['Y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
