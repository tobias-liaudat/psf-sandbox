{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break model notebook\n",
    "\n",
    "Used to 'd√©zinguer' the hybrid models in order to explore the different contributions of each part, the graph-based and the polynomial-based.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pickle\n",
    "import random\n",
    "from ShapePipe.shapepipe.pipeline import file_io\n",
    "from astropy.io import fits\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: \n",
      "fitted_model-2079613-1.npy\n",
      "Dataset path: \n",
      "/Users/tliaudat/Documents/PhD/codes/venv_p3/JB-data/other-JB-data/all_w3_star_cat/star_selection-2079613-1.fits\n"
     ]
    }
   ],
   "source": [
    "W3_RCA_hybrid = '/Users/tliaudat/Documents/PhD/codes/venv_p3/all-W3-tests/test-RCA_hybrid/shapepipe_run_2019-12-20_15-55-23/rca_runner/output/'\n",
    "W3_RCA_PSFEx = '/Users/tliaudat/Documents/PhD/codes/venv_p3/all-W3-tests/test-RCA_PSFEx/shapepipe_run_2019-12-20_15-56-23/rca_runner/output/'\n",
    "\n",
    "try:\n",
    "    os.chdir(W3_RCA_hybrid)\n",
    "except:\n",
    "    a=1\n",
    "    \n",
    "# The model data file patterns\n",
    "CFIS_val_pattern = 'validation_psf-*-*.fits'\n",
    "CFIS_fit_pattern = 'fitted_model-*-*.npy'\n",
    "alt_pattern = 'fitted_model-*-*.npy'\n",
    "\n",
    "\n",
    "# The dataset paths\n",
    "W3_path = '/Users/tliaudat/Documents/PhD/codes/venv_p3/JB-data/other-JB-data/all_w3_star_cat/'\n",
    "red_JB_CCD38 = '/Users/tliaudat/Documents/PhD/codes/venv_p3/JB-data/reduced_CCD-38_dataset/'\n",
    "JB_CCD38 = '/Users/tliaudat/Documents/PhD/codes/venv_p3/JB-data/CCD-38_dataset/'\n",
    "JB_CCD2 = '/Users/tliaudat/Documents/PhD/codes/venv_p3/JB-data/CCD-2_dataset/'\n",
    "CFIS_train_test = '/Users/tliaudat/Documents/PhD/codes/venv_p3/Data_preprocessing/CFIS-data/CFIS_CCDn_38/'\n",
    "\n",
    "# The dataset file pattern\n",
    "patt_JB = 'train-star_selection-*-*.fits'\n",
    "patt_W3 = 'star_selection-*-*.fits'\n",
    "\n",
    "\n",
    "# Select the model and paths to use\n",
    "model_path = W3_RCA_hybrid# model_path_18\n",
    "test_n = 22 # Test number\n",
    "my_pattern = alt_pattern\n",
    "\n",
    "dataset_path = W3_path # JB_CCD38\n",
    "dataset_pattern = patt_W3 # patt_JB\n",
    "\n",
    "# Load the data\n",
    "file_paths = glob.glob(my_pattern)\n",
    "dataset_paths = glob.glob(dataset_path + dataset_pattern)\n",
    "file_paths.sort()\n",
    "dataset_paths.sort()\n",
    "k = 1 # Catalog number\n",
    "print('Model path: \\n' + file_paths[k])\n",
    "print('Dataset path: \\n' + dataset_paths[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3_RCA_hybrid_NOgraph = '/Users/tliaudat/Documents/PhD/codes/venv_p3/all-W3-tests/test-RCA_hybrid/shapepipe_run_2019-12-20_15-55-23/rca_runner/output_NOgraph/'\n",
    "W3_RCA_hybrid_NOPSFEx = '/Users/tliaudat/Documents/PhD/codes/venv_p3/all-W3-tests/test-RCA_hybrid/shapepipe_run_2019-12-20_15-55-23/rca_runner/output_NOPSFEx/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_graph = False\n",
    "clean_PSFEx = True\n",
    "\n",
    "for k in range(len(file_paths)):\n",
    "\n",
    "    # Import the model\n",
    "    model = np.load(file_paths[k],allow_pickle=True)\n",
    "    # Extract the data\n",
    "    data_A = model[1]['A']\n",
    "    data_S = model[1]['S']\n",
    "    data_alpha = model[1]['alpha']\n",
    "    data_VT = model[1]['VT']\n",
    "\n",
    "    if clean_graph == True:\n",
    "        data_alpha[:18,:] = 0\n",
    "        data_alpha[:,:-6] = 0\n",
    "        data_A = data_alpha@data_VT\n",
    "        save_path = W3_RCA_hybrid_NOgraph\n",
    "\n",
    "    elif clean_PSFEx == True:\n",
    "        data_alpha[-6:,:] = 0\n",
    "        data_alpha[:,-6:] = 0\n",
    "        data_A = data_alpha@data_VT\n",
    "        save_path = W3_RCA_hybrid_NOPSFEx\n",
    "        \n",
    "    model[1]['A'] = data_A\n",
    "    model[1]['alpha'] = data_alpha\n",
    "        \n",
    "    \n",
    "    np.save(save_path+file_paths[k],model)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
